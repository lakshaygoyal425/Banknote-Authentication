{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "filename = 'data.txt'\n",
    "#hyperparameters of the algorithm\n",
    "n_folds = 20\n",
    "max_depth = 10\n",
    "min_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splits the data in k folds and returns the concatenated data\n",
    "def k_fold_cross_validation(items, randomize=False):\n",
    "    k=n_folds\n",
    "    if randomize:\n",
    "        items = list(items)\n",
    "        shuffle(items)\n",
    "    slices = [items[i::k] for i in range(k)]\n",
    "    return slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data as well as converting the data into float value. \n",
    "def data(fname):\n",
    "    X,Z=list(),list()\n",
    "    with open(fname,'r') as f:\n",
    "        contents = f.readlines()\n",
    "        Z+= contents\n",
    "    for i in Z:\n",
    "        my_list = i.strip(\"\\n\").strip(\"\\r\").split(\",\")\n",
    "        X.append(my_list)\n",
    "    X = [[float(column) for column in row] for row in X]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gini index for a split dataset\n",
    "def gini(groups,class_values):\n",
    "    gini_value = 0.0\n",
    "    for class_value in class_values:#for each class_value \n",
    "        for group in groups:\n",
    "            number=0.0\n",
    "            size = len(group)\n",
    "            if size == 0:\n",
    "                continue\n",
    "            for row in group:\n",
    "                if(row[-1]==class_value):\n",
    "                    number+=1 #number of rows having the same class_value\n",
    "            ratio= number/float(len(group))\n",
    "            #ratio of the particular class value over the total set of the group\n",
    "            gini_value += (ratio* (1.0 - ratio))#fourmula to calculate the gini index\n",
    "    return gini_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''the data is split in accordance with the k_fold_cross_validation \n",
    "here the data that is already divided into folds is divided into testing and training data\n",
    "with every fold getting the chance of getting the testing data when the other folds are the training data.\n",
    "'''\n",
    "def calculate_accuracy(dataset):\n",
    "    folds=k_fold_cross_validation(dataset)\n",
    "    scores = list()\n",
    "    for i in range(n_folds):\n",
    "        fold_at_i = folds[i]\n",
    "        training=list()\n",
    "        for j in range(n_folds):\n",
    "            if j!=i:\n",
    "                training.append(folds[j])\n",
    "        training = sum(training, [])#removes the error for unhashable types\n",
    "        testing = list()#make a test data list\n",
    "        for row in fold_at_i:\n",
    "            row_copy = list(row)\n",
    "            row_copy[-1] = None#MAKE THE LABEL NONE AND THEN APPEND\n",
    "            testing.append(row_copy)#make the test set\n",
    "        predicted = decision_tree(training, testing)\n",
    "        actual = [row[-1] for row in fold_at_i]\n",
    "        correct_values = 0# Calculate accuracy percentage. pretty straightforward\n",
    "        for i in range(len(actual)):\n",
    "            if (actual[i] == predicted[i]):\n",
    "                correct_values += 1\n",
    "        accuracy= correct_values / float(len(actual)) * 100.0\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best split point for a dataset\n",
    "def splitting(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    node_index=999\n",
    "    node_value=999\n",
    "    node_score=999\n",
    "    node_groups =None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "    #all index values for all the attributes\n",
    "        count=0.0\n",
    "        count_row=0.0\n",
    "        for row in dataset:#here we take the average of the values in a attribute to split the data \n",
    "            count+=1\n",
    "            count_row=row[index]+count_row\n",
    "        count_row=count_row/count\n",
    "        groups=test_split(index,count_row,dataset)\n",
    "        gini_value=gini(groups,class_values)\n",
    "        if gini_value < node_score:#store the values based on which the gini value is the lowest and the splitting is done\n",
    "        #on the basis of that attribute\n",
    "                node_index, node_value, node_score, node_groups = index, row[index], gini_value, groups\n",
    "    return {'i':node_index, 'value':node_value, 'div':node_groups}#return the dictionary containing the details \n",
    "    #on the basis of which the splitting is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value contains highest frequency label from groups\n",
    "def terminal_node(group):\n",
    "    outcomes = [row[-1] for row in group]#this returns all the labels for the data and stores in the outcome list\n",
    "    classify=[0,0]\n",
    "    for out in outcomes:\n",
    "        classify[(int(out))]+=1\n",
    "    if(classify[0]>classify[1]):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create child splits for a node or make terminal\n",
    "def node_split(node,depth):\n",
    "    left, right = node['div']\n",
    "    del(node['div'])\n",
    "    # check if there is no split and the data is coherent. If all the values in the attribute is greater or less that the particular avg value of the attribute\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = terminal_node(left + right)\n",
    "        return\n",
    "    # check for max depth is achieved\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = terminal_node(left), terminal_node(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:#if the mininmum records in the data is less than or equal to the min_size. No splitting\n",
    "        node['left'] = terminal_node(left)\n",
    "    else:\n",
    "        node['left'] = splitting(left)#otherwise split the data further keeping in mind the min_size and the max_depth\n",
    "        node_split(node['left'], depth+1)\n",
    "    # process right child same as above\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = terminal_node(right)\n",
    "    else:\n",
    "        node['right'] = splitting(right)\n",
    "        node_split(node['right'], depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a prediction from the tree\n",
    "def output_from_tree(node, row):\n",
    "    if row[node['i']] < node['value']:\n",
    "        if (type(node['left'])== dict):#if there exists a node['left'] of type dict\n",
    "            return output_from_tree(node['left'], row)\n",
    "        else:\n",
    "            return node['left']#otherwise return the label depicted by the terminal node\n",
    "    else:#same for the right side of the subtree\n",
    "        if (type(node['right'])== dict):\n",
    "            return output_from_tree(node['right'], row)\n",
    "        else:\n",
    "            return node['right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification and Regression Tree Algorithm\n",
    "def decision_tree(train, test):\n",
    "    root= splitting(train)\n",
    "    node_split(root,1)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        prediction = output_from_tree(root, row)\n",
    "        predictions.append(prediction)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 84.697%\n"
     ]
    }
   ],
   "source": [
    "dataset = data(filename)\n",
    "scores = calculate_accuracy(dataset)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/(len(scores))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
